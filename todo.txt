0. more unit tests
   - verify BOOST_CHECK_SMALL vs BOOST_CHECK_CLOSE
   - improve the tests for core data structures (such as table_factor)
1. move to Armadillo's sparse matrices 
2. move to C++11
   - swap for custom iterators
3. drop dependence on Boost for the main template library (keep it for Python bindings and tests)
   - what to do about the range adaptors and iterators?
4. remove much of the custom code like forward_range, range-based algorithms, operator std::string
5. move domain, assignment, etc. to separate data structures
6. variable values, not pointers
7. general code cleanup
   - simplify design wherever possible
   - parallel-friendly
   - performance (speed + memory) - 
   - facebook formatting guidelines wrt the newline after ( +
   - trailing underscore for member vars
   - allow edge creation outside of the graph
   - rename random_table_factor_functor to table_factor_generator and
     change the function signatures from generate_xxx to operator(),
     so that the generator can be used directly e.g in loopy bp 
     without adapters
   - get rid of the SWIG nonsense
   - make sure triangulation does not construct properties
   - clean up record or merge it with assignment
   - replace template arguments for optimization objective/gradient
     with std::function
   - fix table_factor::operator=(double)
   - rename shafer_shenoy and hugin to something more memorable
     and split junction tree inference to two files
   - possibly merge the pairwise_markov_network class with markov_network
   - clean up the factor_graph template
   - decomposable - move the extra normalization out of the impl namespace
   - test if we can eliminate the marginal with pre-allocated output
   - clean up the concepts especially factors
   - remove extra typedefs from table_factor and other factor classes
   - implement d-separation in Markov network and Bayesian network classes
   - get rid of member functions in decomposable that create functors
   - consider deprecating Factor::var_vector_type, var_map_type
   - convert learn_factor<F> to a functor table_factor_learner<T> etc.
   - rewrite dataset to use simpler interfaces and verify timing
   - standardize vertex vs node in graphical models
   - bayesian_network modifiers - check add_factor
   - flatten, relative entropy for decomposable
   - ensure the newdatasets work with CRFs
   - fix chow-liu
   - more efficient sampling from BNs and decomposable models
   - try different initialization once we have better sampling of MGs
   - clean up the subset_iterator code
   - marginal() test => is_marginal() 
   - merged datasets
   - change the table generator to take actual arguments (not logspace)
   - refactor the CRF factors
   - clean up and simplify the optimization code
   - marginal() => is_marginal(), standardize arg_vector, head_vector() etc.
   - get rid of hacks in the table_factor and dense_table
   - simplify the storage format of vector datasets
   - implement pseudolikelihood for factor graphs
     - possibly clean up factor graphs
   - clean up the CRF factors, models, and learning
   - improve the safety of *_network wrt factor mutations

8. more examples / applications:
   - viterbi algorithm

Python:
- change many asserts to exceptions
